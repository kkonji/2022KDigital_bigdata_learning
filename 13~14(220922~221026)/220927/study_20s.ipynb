{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텍스트 분류- 뉴스\n",
    "- 자연어 처리 + RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, SimpleRNN, LSTM, GRU, Embedding, Bidirectional\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import set_random_seed, pad_sequences, to_categorical, plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = fetch_20newsgroups(subset='all', remove=('footers', 'headers'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = group['data']\n",
    "target = group['target']\n",
    "target_names = group['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_names: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "target_names 수: 20\n"
     ]
    }
   ],
   "source": [
    "# print(f\"data: {data}\")\n",
    "# print(f\"target: {target}\")\n",
    "print(f\"target_names: {target_names}\")\n",
    "print(f\"target_names 수: {len(target_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP 자연어처리\n",
    "1. 자연어 -> 단어사전\n",
    "2. 단어사전 -> 수치화\n",
    "3. 패딩으로 길이 동일하게 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 자연어 -> 단어사전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "sw = nltk.corpus.stopwords.words(\"english\")\n",
    "total_token = []\n",
    "for j in data:\n",
    "    total_token.append([i for i in word_tokenize(j) if i not in sw])\n",
    "print(len(total_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 단어사전 -> 수치화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18846"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 141, 1, 2310, 1156, 354, 2807, 1082, 307, 1159, 987, 2310, 2321, 3004, 4, 189, 3, 8, 241, 1, 241, 1, 4, 166, 3, 8, 109, 185, 267, 1, 29, 3490, 241, 6489, 2310, 4, 299, 3, 1242, 3004, 1049, 8, 276, 4, 4462, 1699, 66, 121, 1198, 604, 1787, 4, 94, 48, 193, 1, 1657, 1042, 1905, 4, 6575, 152, 4462, 193, 1657, 277, 480, 350, 97, 2310, 109, 1724, 1, 3446, 458, 4, 8, 1, 65, 2955, 1612, 953, 1198, 604, 188, 4, 2310, 1089, 17, 17, 17]\n",
      "[6941, 1, 1782, 1988, 62, 585, 267, 1, 1761, 130, 615, 17, 1, 18, 470, 9, 7, 1, 6, 1, 107, 548, 340, 400, 9, 548, 1, 4, 2205]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_1100\\349335917.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  token_num = np.array(tk.texts_to_sequences(total_token))\n"
     ]
    }
   ],
   "source": [
    "tk = Tokenizer(num_words=7000, oov_token=1)  # num_words=7000, oov_token='oov'\n",
    "tk.fit_on_texts(total_token)\n",
    "# print(tk.word_index)\n",
    "# print(tk.word_counts)\n",
    "# 문장에서 생성된 사전(voca)을 기반으로 수치화\n",
    "# print(tk.texts_to_sequences(total_token))\n",
    "token_num = np.array(tk.texts_to_sequences(total_token))\n",
    "print(token_num[0])\n",
    "print(token_num.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213450\n"
     ]
    }
   ],
   "source": [
    "print(len(tk.word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6899\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "for val in tk.word_counts.values():\n",
    "    if val > 50 :\n",
    "        a.append(val)\n",
    "print(len(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median([val for val in tk.word_counts.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "tfvector = TfidfVectorizer()\n",
    "tfvector.fit(data)\n",
    "data_t = tfvector.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 값 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVX0lEQVR4nO3df7DddZ3f8eeribDWXwS5zUTCNsFGO+BsI2YQZ9WhskJgHdFOxyZ/LNGlRit01tqZbagzxXXLDLpat8xaFNdU6CjIipYMxWJknHX7gx8XjZAomEuIJZlArqDSrjusuO/+cT7X/Sbfm+Tmnpucw+T5mPnO+X7f31/vk3NyX+f749ybqkKSpK6/M+oGJEnjx3CQJPUYDpKkHsNBktRjOEiSehaPuoH5Ou2002rFihWjbkOSnlceeOCBH1fVxJGWe96Gw4oVK5icnBx1G5L0vJLkR3NZztNKkqQew0GS1GM4SJJ6DAdJUo/hIEnqMRwkST2GgySpx3CQJPUYDpKknuftN6SHsWLTfxvJfndf+9sj2a8kHS2PHCRJPYaDJKnHcJAk9RgOkqQew0GS1GM4SJJ6DAdJUo/hIEnqMRwkST2GgySp54jhkGRzkv1JtndqX06yrQ27k2xr9RVJ/qoz7zOddV6X5KEkU0muS5JWPzXJ1iQ72+OSY/A8JUlHYS5HDl8A1nYLVfXPqmp1Va0GbgO+2pn96My8qnp/p3498F5gVRtmtrkJuLuqVgF3t2lJ0ggdMRyq6tvA07PNa5/+3wXcfLhtJFkGvLSq7qmqAm4C3tFmXwrc2MZv7NQlSSMy7DWHNwFPVtXOTm1lku8m+fMkb2q104E9nWX2tBrA0qra18afAJYeamdJNiaZTDI5PT09ZOuSpEMZNhzWc+BRwz7g16vqtcCHgC8leelcN9aOKuow82+oqjVVtWZiYmK+PUuSjmDef88hyWLgnwCvm6lV1bPAs238gSSPAq8C9gLLO6svbzWAJ5Msq6p97fTT/vn2JElaGMMcOfwW8HBV/ep0UZKJJIva+JkMLjzvaqeNnklyXrtOcRlwe1ttC7ChjW/o1CVJIzKXW1lvBv438Ooke5Jc3mato38h+s3Ag+3W1q8A76+qmYvZHwD+FJgCHgW+3urXAm9NspNB4Fw7/6cjSVoIRzytVFXrD1F/9yy12xjc2jrb8pPAa2apPwVccKQ+JEnHj9+QliT1GA6SpB7DQZLUYzhIknoMB0lSj+EgSeoxHCRJPYaDJKnHcJAk9RgOkqQew0GS1GM4SJJ6DAdJUo/hIEnqMRwkST2GgySpx3CQJPUYDpKkHsNBktRzxHBIsjnJ/iTbO7WPJNmbZFsbLunMuyrJVJJHklzUqa9ttakkmzr1lUnubfUvJzlpIZ+gJOnozeXI4QvA2lnqn6qq1W24EyDJWcA64Oy2zn9KsijJIuDTwMXAWcD6tizAx9q2/gHwE+DyYZ6QJGl4RwyHqvo28PQct3cpcEtVPVtVjwFTwLltmKqqXVX118AtwKVJArwF+Epb/0bgHUf3FCRJC22Yaw5XJnmwnXZa0mqnA493ltnTaoeqvxz4aVU9d1B9Vkk2JplMMjk9PT1E65Kkw5lvOFwPvBJYDewDPrlQDR1OVd1QVWuqas3ExMTx2KUknZAWz2elqnpyZjzJ54A72uRe4IzOostbjUPUnwJOSbK4HT10l5ckjci8jhySLOtMvhOYuZNpC7AuyclJVgKrgPuA+4FV7c6kkxhctN5SVQV8C/inbf0NwO3z6UmStHCOeOSQ5GbgfOC0JHuAq4Hzk6wGCtgNvA+gqnYkuRX4PvAccEVV/bJt50rgLmARsLmqdrRd/BvgliT/Hvgu8PmFenKSpPk5YjhU1fpZyof8AV5V1wDXzFK/E7hzlvouBnczSZLGhN+QliT1GA6SpB7DQZLUYzhIknoMB0lSj+EgSeoxHCRJPYaDJKnHcJAk9RgOkqQew0GS1GM4SJJ6DAdJUo/hIEnqMRwkST2GgySpx3CQJPUYDpKkniOGQ5LNSfYn2d6p/VGSh5M8mORrSU5p9RVJ/irJtjZ8prPO65I8lGQqyXVJ0uqnJtmaZGd7XHIMnqck6SjM5cjhC8Dag2pbgddU1W8APwSu6sx7tKpWt+H9nfr1wHuBVW2Y2eYm4O6qWgXc3aYlSSN0xHCoqm8DTx9U+0ZVPdcm7wGWH24bSZYBL62qe6qqgJuAd7TZlwI3tvEbO3VJ0ogsxDWH3wW+3plemeS7Sf48yZta7XRgT2eZPa0GsLSq9rXxJ4Clh9pRko1JJpNMTk9PL0DrkqTZDBUOST4MPAd8sZX2Ab9eVa8FPgR8KclL57q9dlRRh5l/Q1Wtqao1ExMTQ3QuSTqcxfNdMcm7gbcBF7Qf6lTVs8CzbfyBJI8CrwL2cuCpp+WtBvBkkmVVta+dfto/354kSQtjXkcOSdYCvw+8vap+3qlPJFnUxs9kcOF5Vztt9EyS89pdSpcBt7fVtgAb2viGTl2SNCJHPHJIcjNwPnBakj3A1QzuTjoZ2NruSL2n3Zn0ZuCjSX4B/A3w/qqauZj9AQZ3Pr2QwTWKmesU1wK3Jrkc+BHwrgV5ZpKkeTtiOFTV+lnKnz/EsrcBtx1i3iTwmlnqTwEXHKkPSdLx4zekJUk9hoMkqcdwkCT1GA6SpB7DQZLUYzhIknoMB0lSj+EgSeoxHCRJPYaDJKnHcJAk9RgOkqQew0GS1GM4SJJ6DAdJUo/hIEnqMRwkST2GgySpx3CQJPXMKRySbE6yP8n2Tu3UJFuT7GyPS1o9Sa5LMpXkwSTndNbZ0JbfmWRDp/66JA+1da5LkoV8kpKkozPXI4cvAGsPqm0C7q6qVcDdbRrgYmBVGzYC18MgTICrgdcD5wJXzwRKW+a9nfUO3pck6TiaUzhU1beBpw8qXwrc2MZvBN7Rqd9UA/cApyRZBlwEbK2qp6vqJ8BWYG2b99KquqeqCripsy1J0ggMc81haVXta+NPAEvb+OnA453l9rTa4ep7Zqn3JNmYZDLJ5PT09BCtS5IOZ0EuSLdP/LUQ2zrCfm6oqjVVtWZiYuJY706STljDhMOT7ZQQ7XF/q+8Fzugst7zVDldfPktdkjQiw4TDFmDmjqMNwO2d+mXtrqXzgJ+10093ARcmWdIuRF8I3NXmPZPkvHaX0mWdbUmSRmDxXBZKcjNwPnBakj0M7jq6Frg1yeXAj4B3tcXvBC4BpoCfA+8BqKqnk/whcH9b7qNVNXOR+wMM7oh6IfD1NkiSRmRO4VBV6w8x64JZli3gikNsZzOweZb6JPCaufQiSTr2/Ia0JKnHcJAk9RgOkqQew0GS1GM4SJJ6DAdJUo/hIEnqMRwkST2GgySpx3CQJPUYDpKkHsNBktRjOEiSegwHSVKP4SBJ6jEcJEk9hoMkqcdwkCT1zDsckrw6ybbO8EySDyb5SJK9nfolnXWuSjKV5JEkF3Xqa1ttKsmmYZ+UJGk4c/ob0rOpqkeA1QBJFgF7ga8B7wE+VVWf6C6f5CxgHXA28Argm0le1WZ/GngrsAe4P8mWqvr+fHuTJA1n3uFwkAuAR6vqR0kOtcylwC1V9SzwWJIp4Nw2b6qqdgEkuaUtazhI0ogs1DWHdcDNnekrkzyYZHOSJa12OvB4Z5k9rXaoek+SjUkmk0xOT08vUOuSpIMNHQ5JTgLeDvxZK10PvJLBKad9wCeH3ceMqrqhqtZU1ZqJiYmF2qwk6SALcVrpYuA7VfUkwMwjQJLPAXe0yb3AGZ31lrcah6lLkkZgIU4rradzSinJss68dwLb2/gWYF2Sk5OsBFYB9wH3A6uSrGxHIevaspKkERnqyCHJixjcZfS+TvnjSVYDBeyemVdVO5LcyuBC83PAFVX1y7adK4G7gEXA5qraMUxfkqThDBUOVfWXwMsPqv3OYZa/BrhmlvqdwJ3D9CJJWjh+Q1qS1GM4SJJ6DAdJUo/hIEnqMRwkST2GgySpx3CQJPUYDpKkHsNBktRjOEiSegwHSVKP4SBJ6jEcJEk9hoMkqcdwkCT1GA6SpB7DQZLUYzhIknoMB0lSz9DhkGR3koeSbEsy2WqnJtmaZGd7XNLqSXJdkqkkDyY5p7OdDW35nUk2DNuXJGn+FurI4R9X1eqqWtOmNwF3V9Uq4O42DXAxsKoNG4HrYRAmwNXA64FzgatnAkWSdPwdq9NKlwI3tvEbgXd06jfVwD3AKUmWARcBW6vq6ar6CbAVWHuMepMkHcFChEMB30jyQJKNrba0qva18SeApW38dODxzrp7Wu1Q9QMk2ZhkMsnk9PT0ArQuSZrN4gXYxhuram+SvwdsTfJwd2ZVVZJagP1QVTcANwCsWbNmQbYpSeob+sihqva2x/3A1xhcM3iynS6iPe5vi+8FzuisvrzVDlWXJI3AUOGQ5EVJXjIzDlwIbAe2ADN3HG0Abm/jW4DL2l1L5wE/a6ef7gIuTLKkXYi+sNUkSSMw7GmlpcDXksxs60tV9d+T3A/cmuRy4EfAu9rydwKXAFPAz4H3AFTV00n+ELi/LffRqnp6yN4kSfM0VDhU1S7gH81Sfwq4YJZ6AVccYlubgc3D9CNJWhh+Q1qS1GM4SJJ6DAdJUo/hIEnqMRwkST2GgySpx3CQJPUYDpKkHsNBktRjOEiSegwHSVKP4SBJ6jEcJEk9hoMkqcdwkCT1GA6SpB7DQZLUYzhIknrmHQ5JzkjyrSTfT7Ijye+1+keS7E2yrQ2XdNa5KslUkkeSXNSpr221qSSbhntKkqRhDfM3pJ8D/nVVfSfJS4AHkmxt8z5VVZ/oLpzkLGAdcDbwCuCbSV7VZn8aeCuwB7g/yZaq+v4QvUmShjDvcKiqfcC+Nv5/k/wAOP0wq1wK3FJVzwKPJZkCzm3zpqpqF0CSW9qyhoMkjciCXHNIsgJ4LXBvK12Z5MEkm5MsabXTgcc7q+1ptUPVZ9vPxiSTSSanp6cXonVJ0iyGDockLwZuAz5YVc8A1wOvBFYzOLL45LD7mFFVN1TVmqpaMzExsVCblSQdZJhrDiR5AYNg+GJVfRWgqp7szP8ccEeb3Auc0Vl9eatxmLokaQSGuVspwOeBH1TVf+jUl3UWeyewvY1vAdYlOTnJSmAVcB9wP7AqycokJzG4aL1lvn1JkoY3zJHDbwK/AzyUZFur/VtgfZLVQAG7gfcBVNWOJLcyuND8HHBFVf0SIMmVwF3AImBzVe0Yoi9J0pCGuVvpfwCZZdadh1nnGuCaWep3Hm49SdLx5TekJUk9hoMkqcdwkCT1GA6SpB7DQZLUYzhIknoMB0lSj+EgSeoxHCRJPYaDJKnHcJAk9RgOkqQew0GS1GM4SJJ6DAdJUo/hIEnqMRwkST2GgySpx3CQJPWMTTgkWZvkkSRTSTaNuh9JOpGNRTgkWQR8GrgYOAtYn+Ss0XYlSSeusQgH4Fxgqqp2VdVfA7cAl464J0k6YS0edQPN6cDjnek9wOsPXijJRmBjm/x/SR6Z5/5OA348z3XnLR+b02Ij6W0O7OvojWtv49oXjG9v49oXHH1vf38uC41LOMxJVd0A3DDsdpJMVtWaBWhpwY1rb/Z19Ma1t3HtC8a3t3HtC45db+NyWmkvcEZnenmrSZJGYFzC4X5gVZKVSU4C1gFbRtyTJJ2wxuK0UlU9l+RK4C5gEbC5qnYcw10OfWrqGBrX3uzr6I1rb+PaF4xvb+PaFxyj3lJVx2K7kqTnsXE5rSRJGiOGgySp54QLh+PxazqSbE6yP8n2Tu3UJFuT7GyPS1o9Sa5r/TyY5JzOOhva8juTbOjUX5fkobbOdUkyx77OSPKtJN9PsiPJ741Rb7+W5L4k32u9/UGrr0xyb9vel9sNCyQ5uU1PtfkrOtu6qtUfSXJRpz7v1z7JoiTfTXLHuPSVZHf7t96WZLLVRv5atnVPSfKVJA8n+UGSN4y6tySvbv9WM8MzST446r466/6rDN7725PcnMH/idG9z6rqhBkYXOx+FDgTOAn4HnDWMdjPm4FzgO2d2seBTW18E/CxNn4J8HUgwHnAva1+KrCrPS5p40vavPvasmnrXjzHvpYB57TxlwA/ZPDrSsahtwAvbuMvAO5t27kVWNfqnwH+RRv/APCZNr4O+HIbP6u9ricDK9vrvWjY1x74EPAl4I42PfK+gN3AaQfVRv5atnVvBP55Gz8JOGVceuv8LHiCwRfCRt4Xgy8CPwa8sPP+evco32cj/4F9PAfgDcBdnemrgKuO0b5WcGA4PAIsa+PLgEfa+GeB9QcvB6wHPtupf7bVlgEPd+oHLHeUPd4OvHXcegP+LvAdBt+S/zGw+ODXj8GdbW9o44vbcjn4NZ1ZbpjXnsH3bu4G3gLc0fYzDn3tph8OI38tgZcx+EGXceuts86FwP8cl774298ScWp739wBXDTK99mJdlpptl/Tcfpx2vfSqtrXxp8Alh6hp8PV98xSPyrtMPS1DD6hj0VvGZy62QbsB7Yy+KTz06p6bpbt/aqHNv9nwMvn0fNc/DHw+8DftOmXj0lfBXwjyQMZ/GoZGI/XciUwDfznDE7F/WmSF41JbzPWATe38ZH3VVV7gU8A/wfYx+B98wAjfJ+daOEwFmoQ3SO7hzjJi4HbgA9W1TPdeaPsrap+WVWrGXxSPxf4h6PooyvJ24D9VfXAqHuZxRur6hwGv834iiRv7s4c4Wu5mMFp1eur6rXAXzI4XTMOvdHO278d+LOD542qr3ad41IGwfoK4EXA2uPdR9eJFg6j/DUdTyZZBtAe9x+hp8PVl89Sn5MkL2AQDF+sqq+OU28zquqnwLcYHAqfkmTmy5rd7f2qhzb/ZcBT8+j5SH4TeHuS3Qx+W/BbgP84Bn3NfNqkqvYDX2MQqOPwWu4B9lTVvW36KwzCYhx6g0GYfqeqnmzT49DXbwGPVdV0Vf0C+CqD997o3mdHc57u+T4w+ESzi0E6z1yUOfsY7WsFB15z+CMOvOj18Tb+2xx40eu+Vj+VwXnbJW14DDi1zTv4otclc+wpwE3AHx9UH4feJoBT2vgLgb8A3sbg0133gtwH2vgVHHhB7tY2fjYHXpDbxeBi3NCvPXA+f3tBeqR9Mfhk+ZLO+P9i8Elz5K9lW/cvgFe38Y+0vsalt1uA94zZ+//1wA4G19vC4IL+vxzl+2zkP7CP98DgDoQfMjif/eFjtI+bGZw3/AWDT1GXMzgfeDewE/hm580UBn/o6FHgIWBNZzu/C0y1oftmXgNsb+v8CQdd+DtMX29kcMj8ILCtDZeMSW+/AXy39bYd+Hetfmb7DzfV/qOc3Oq/1qan2vwzO9v6cNv/I3TuFhn2tefAcBhpX23/32vDjpn1xuG1bOuuBibb6/lfGfwQHXlvDIL0KeBlndrI+2rr/gHwcFv/vzD4AT+y95m/PkOS1HOiXXOQJM2B4SBJ6jEcJEk9hoMkqcdwkCT1GA6SpB7DQZLU8/8BtCgNb+krzSAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(i) for i in token_num])\n",
    "plt.show()\n",
    "plt.boxplot([len(i) for i in token_num])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121.0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median([len(i) for i in token_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846\n"
     ]
    }
   ],
   "source": [
    "token_num = pad_sequences(token_num, maxlen=200)\n",
    "print(len(token_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 분리 (train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(token_num, target, stratify=target, test_size=0.2, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, stratify=y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12060, 200) (12060,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 타겟 값 범주화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 100, 20)           10000     \n",
      "                                                                 \n",
      " simple_rnn_3 (SimpleRNN)    (None, 10)                310       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 20)                220       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,530\n",
      "Trainable params: 10,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 구성\n",
    "md = Sequential()\n",
    "md.add(Embedding(7000, 20, input_length=100))  \n",
    "md.add(SimpleRNN(units=10))\n",
    "md.add(Dense(20, activation='softmax'))\n",
    "md.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "377/377 [==============================] - 6s 14ms/step - loss: 2.8770 - accuracy: 0.0833 - val_loss: 2.7574 - val_accuracy: 0.0971\n",
      "Epoch 2/100\n",
      "377/377 [==============================] - 5s 14ms/step - loss: 2.7250 - accuracy: 0.1039 - val_loss: 2.7038 - val_accuracy: 0.1005\n",
      "Epoch 3/100\n",
      "377/377 [==============================] - 5s 13ms/step - loss: 2.6609 - accuracy: 0.1260 - val_loss: 2.6692 - val_accuracy: 0.1154\n",
      "Epoch 4/100\n",
      "377/377 [==============================] - 5s 14ms/step - loss: 2.6271 - accuracy: 0.1372 - val_loss: 2.6659 - val_accuracy: 0.1121\n",
      "Epoch 5/100\n",
      "377/377 [==============================] - 6s 15ms/step - loss: 2.5909 - accuracy: 0.1456 - val_loss: 2.6102 - val_accuracy: 0.1174\n",
      "Epoch 6/100\n",
      "377/377 [==============================] - 5s 14ms/step - loss: 2.5598 - accuracy: 0.1538 - val_loss: 2.5962 - val_accuracy: 0.1240\n",
      "Epoch 7/100\n",
      "377/377 [==============================] - 5s 14ms/step - loss: 2.5365 - accuracy: 0.1671 - val_loss: 2.6527 - val_accuracy: 0.1223\n",
      "Epoch 8/100\n",
      "377/377 [==============================] - 5s 14ms/step - loss: 2.5078 - accuracy: 0.1692 - val_loss: 2.5693 - val_accuracy: 0.1353\n",
      "Epoch 9/100\n",
      "377/377 [==============================] - 5s 14ms/step - loss: 2.4909 - accuracy: 0.1803 - val_loss: 2.5892 - val_accuracy: 0.1363\n",
      "Epoch 10/100\n",
      "377/377 [==============================] - 5s 14ms/step - loss: 2.4622 - accuracy: 0.1905 - val_loss: 2.5704 - val_accuracy: 0.1379\n",
      "Epoch 11/100\n",
      "377/377 [==============================] - 5s 14ms/step - loss: 2.4442 - accuracy: 0.1947 - val_loss: 2.5486 - val_accuracy: 0.1396\n",
      "Epoch 12/100\n",
      "377/377 [==============================] - 5s 14ms/step - loss: 2.4252 - accuracy: 0.2043 - val_loss: 2.6015 - val_accuracy: 0.1373\n",
      "Epoch 13/100\n",
      "377/377 [==============================] - 6s 16ms/step - loss: 2.4072 - accuracy: 0.2053 - val_loss: 2.5467 - val_accuracy: 0.1459\n",
      "Epoch 14/100\n",
      "377/377 [==============================] - 7s 17ms/step - loss: 2.3865 - accuracy: 0.2172 - val_loss: 2.5527 - val_accuracy: 0.1489\n",
      "Epoch 15/100\n",
      "377/377 [==============================] - 6s 17ms/step - loss: 2.3715 - accuracy: 0.2211 - val_loss: 2.5617 - val_accuracy: 0.1582\n",
      "Epoch 16/100\n",
      "377/377 [==============================] - 6s 16ms/step - loss: 2.3542 - accuracy: 0.2277 - val_loss: 2.5540 - val_accuracy: 0.1568\n",
      "Epoch 17/100\n",
      "377/377 [==============================] - 6s 16ms/step - loss: 2.3348 - accuracy: 0.2303 - val_loss: 2.5530 - val_accuracy: 0.1588\n",
      "Epoch 18/100\n",
      "377/377 [==============================] - 6s 15ms/step - loss: 2.3224 - accuracy: 0.2396 - val_loss: 2.5814 - val_accuracy: 0.1671\n",
      "Epoch 19/100\n",
      "377/377 [==============================] - 6s 16ms/step - loss: 2.3049 - accuracy: 0.2437 - val_loss: 2.5593 - val_accuracy: 0.1631\n",
      "Epoch 20/100\n",
      "377/377 [==============================] - 6s 16ms/step - loss: 2.2977 - accuracy: 0.2443 - val_loss: 2.5679 - val_accuracy: 0.1681\n",
      "Epoch 21/100\n",
      "377/377 [==============================] - 6s 16ms/step - loss: 2.2857 - accuracy: 0.2504 - val_loss: 2.5904 - val_accuracy: 0.1625\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성 및 학습\n",
    "md.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', patience=8)\n",
    "mcp = ModelCheckpoint(filepath='best_model_rmsprop.h5', monitor='val_loss', save_best_only=True)\n",
    "history = md.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[es, mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 0s 4ms/step - loss: 2.5724 - accuracy: 0.1568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5723774433135986, 0.1567639261484146]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "md.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, 200, 1000)         7000000   \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 10)                40440     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 20)                220       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,040,660\n",
      "Trainable params: 7,040,660\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 구성\n",
    "md2 = Sequential()\n",
    "md2.add(Embedding(7000, 1000, input_length=200))  \n",
    "md2.add(LSTM(units=10, dropout=0.3, recurrent_dropout=0.3))\n",
    "md2.add(Dense(20, activation='softmax'))\n",
    "md2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "377/377 [==============================] - 231s 607ms/step - loss: 2.7671 - accuracy: 0.1496 - val_loss: 2.6110 - val_accuracy: 0.2023\n",
      "Epoch 2/100\n",
      "377/377 [==============================] - 233s 617ms/step - loss: 2.2741 - accuracy: 0.2963 - val_loss: 2.3010 - val_accuracy: 0.3017\n",
      "Epoch 3/100\n",
      "377/377 [==============================] - 229s 608ms/step - loss: 1.8446 - accuracy: 0.4743 - val_loss: 1.8154 - val_accuracy: 0.4708\n",
      "Epoch 4/100\n",
      "377/377 [==============================] - 224s 595ms/step - loss: 1.4013 - accuracy: 0.6267 - val_loss: 1.4904 - val_accuracy: 0.5945\n",
      "Epoch 5/100\n",
      "377/377 [==============================] - 223s 592ms/step - loss: 1.0380 - accuracy: 0.7402 - val_loss: 1.2674 - val_accuracy: 0.6645\n",
      "Epoch 6/100\n",
      "377/377 [==============================] - 223s 592ms/step - loss: 0.7571 - accuracy: 0.8154 - val_loss: 1.1022 - val_accuracy: 0.6989\n",
      "Epoch 7/100\n",
      "377/377 [==============================] - 221s 587ms/step - loss: 0.5629 - accuracy: 0.8663 - val_loss: 1.0506 - val_accuracy: 0.7152\n",
      "Epoch 8/100\n",
      "377/377 [==============================] - 225s 598ms/step - loss: 0.4245 - accuracy: 0.9006 - val_loss: 1.0382 - val_accuracy: 0.7225\n",
      "Epoch 9/100\n",
      "377/377 [==============================] - 233s 617ms/step - loss: 0.3294 - accuracy: 0.9212 - val_loss: 1.0510 - val_accuracy: 0.7304\n",
      "Epoch 10/100\n",
      "377/377 [==============================] - 231s 614ms/step - loss: 0.2681 - accuracy: 0.9352 - val_loss: 1.0459 - val_accuracy: 0.7321\n",
      "Epoch 11/100\n",
      "377/377 [==============================] - 233s 617ms/step - loss: 0.2221 - accuracy: 0.9478 - val_loss: 1.1027 - val_accuracy: 0.7265\n",
      "Epoch 12/100\n",
      "377/377 [==============================] - 237s 628ms/step - loss: 0.1866 - accuracy: 0.9547 - val_loss: 1.1329 - val_accuracy: 0.7238\n",
      "Epoch 13/100\n",
      "377/377 [==============================] - 226s 599ms/step - loss: 0.1576 - accuracy: 0.9618 - val_loss: 1.1632 - val_accuracy: 0.7275\n",
      "Epoch 14/100\n",
      "377/377 [==============================] - 229s 608ms/step - loss: 0.1363 - accuracy: 0.9662 - val_loss: 1.2280 - val_accuracy: 0.7132\n",
      "Epoch 15/100\n",
      "377/377 [==============================] - 227s 602ms/step - loss: 0.1201 - accuracy: 0.9707 - val_loss: 1.2273 - val_accuracy: 0.7182\n",
      "Epoch 16/100\n",
      "377/377 [==============================] - 227s 602ms/step - loss: 0.1074 - accuracy: 0.9744 - val_loss: 1.2344 - val_accuracy: 0.7238\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성 및 학습\n",
    "md2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', patience=8)\n",
    "mcp = ModelCheckpoint(filepath='best_model_lstm_dropout2.h5', monitor='val_loss', save_best_only=True)\n",
    "history = md2.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[es, mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 8s 65ms/step - loss: 1.2133 - accuracy: 0.7273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2132810354232788, 0.7273209691047668]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "md2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 200, 2000)         8000000   \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 10)                60360     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 20)                220       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,060,580\n",
      "Trainable params: 8,060,580\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 구성\n",
    "md3 = Sequential()\n",
    "md3.add(Embedding(4000, 2000, input_length=200))  \n",
    "md3.add(GRU(units=10))\n",
    "md3.add(Dense(20, activation='softmax'))\n",
    "md3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "377/377 [==============================] - 91s 236ms/step - loss: 2.6328 - accuracy: 0.2096 - val_loss: 2.1156 - val_accuracy: 0.3853\n",
      "Epoch 2/100\n",
      "377/377 [==============================] - 91s 242ms/step - loss: 1.7079 - accuracy: 0.5539 - val_loss: 1.6092 - val_accuracy: 0.5653\n",
      "Epoch 3/100\n",
      "377/377 [==============================] - 92s 244ms/step - loss: 1.2446 - accuracy: 0.6766 - val_loss: 1.4626 - val_accuracy: 0.5796\n",
      "Epoch 4/100\n",
      "377/377 [==============================] - 91s 241ms/step - loss: 0.9786 - accuracy: 0.7457 - val_loss: 1.4171 - val_accuracy: 0.5872\n",
      "Epoch 5/100\n",
      "377/377 [==============================] - 95s 252ms/step - loss: 0.7955 - accuracy: 0.7968 - val_loss: 1.4169 - val_accuracy: 0.5822\n",
      "Epoch 6/100\n",
      "377/377 [==============================] - 90s 240ms/step - loss: 0.6567 - accuracy: 0.8347 - val_loss: 1.4515 - val_accuracy: 0.5832\n",
      "Epoch 7/100\n",
      "377/377 [==============================] - 91s 242ms/step - loss: 0.5641 - accuracy: 0.8557 - val_loss: 1.5061 - val_accuracy: 0.5736\n",
      "Epoch 8/100\n",
      "377/377 [==============================] - 91s 242ms/step - loss: 0.4985 - accuracy: 0.8750 - val_loss: 1.5369 - val_accuracy: 0.5782\n",
      "Epoch 9/100\n",
      "377/377 [==============================] - 93s 246ms/step - loss: 0.4281 - accuracy: 0.8940 - val_loss: 1.5676 - val_accuracy: 0.5763\n",
      "Epoch 10/100\n",
      "377/377 [==============================] - 92s 243ms/step - loss: 0.3764 - accuracy: 0.9109 - val_loss: 1.6166 - val_accuracy: 0.5829\n",
      "Epoch 11/100\n",
      "377/377 [==============================] - 92s 245ms/step - loss: 0.3236 - accuracy: 0.9237 - val_loss: 1.6688 - val_accuracy: 0.5706\n",
      "Epoch 12/100\n",
      "377/377 [==============================] - 91s 242ms/step - loss: 0.2911 - accuracy: 0.9337 - val_loss: 1.7300 - val_accuracy: 0.5610\n",
      "Epoch 13/100\n",
      "377/377 [==============================] - 91s 242ms/step - loss: 0.2818 - accuracy: 0.9343 - val_loss: 1.7596 - val_accuracy: 0.5633\n",
      "Epoch 14/100\n",
      "377/377 [==============================] - 92s 243ms/step - loss: 0.2777 - accuracy: 0.9299 - val_loss: 1.8110 - val_accuracy: 0.5676\n",
      "Epoch 15/100\n",
      "377/377 [==============================] - 92s 245ms/step - loss: 0.2426 - accuracy: 0.9409 - val_loss: 1.8084 - val_accuracy: 0.5716\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성 및 학습\n",
    "md3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', patience=8)\n",
    "mcp = ModelCheckpoint(filepath='best_model_gru.h5', monitor='val_loss', save_best_only=True)\n",
    "history = md3.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[es, mcp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 6s 51ms/step - loss: 1.8148 - accuracy: 0.5844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8148125410079956, 0.5843501091003418]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "md3.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 양방향 RNN 적용\n",
    "- Bidirectional 함수 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_13 (Embedding)    (None, 200, 1000)         7000000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 20)               80880     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,081,300\n",
      "Trainable params: 7,081,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 구성\n",
    "md4 = Sequential()\n",
    "md4.add(Embedding(7000, 1000, input_length=200))  \n",
    "md4.add(Bidirectional(LSTM(units=10, dropout=0.3)) )\n",
    "md4.add(Dense(20, activation='softmax'))\n",
    "md4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "377/377 [==============================] - 165s 430ms/step - loss: 2.7479 - accuracy: 0.1498 - val_loss: 2.4233 - val_accuracy: 0.2344\n",
      "Epoch 2/100\n",
      "377/377 [==============================] - 166s 440ms/step - loss: 2.0977 - accuracy: 0.3616 - val_loss: 1.9843 - val_accuracy: 0.3969\n",
      "Epoch 3/100\n",
      "377/377 [==============================] - 164s 436ms/step - loss: 1.5510 - accuracy: 0.5552 - val_loss: 1.6400 - val_accuracy: 0.5056\n",
      "Epoch 4/100\n",
      "377/377 [==============================] - 165s 439ms/step - loss: 1.1105 - accuracy: 0.7075 - val_loss: 1.4309 - val_accuracy: 0.5836\n",
      "Epoch 5/100\n",
      "377/377 [==============================] - 168s 446ms/step - loss: 0.8038 - accuracy: 0.7973 - val_loss: 1.3675 - val_accuracy: 0.6028\n",
      "Epoch 6/100\n",
      "377/377 [==============================] - 167s 443ms/step - loss: 0.5374 - accuracy: 0.8683 - val_loss: 1.0780 - val_accuracy: 0.6837\n",
      "Epoch 7/100\n",
      "377/377 [==============================] - 168s 445ms/step - loss: 0.3001 - accuracy: 0.9252 - val_loss: 1.0312 - val_accuracy: 0.7042\n",
      "Epoch 8/100\n",
      " 15/377 [>.............................] - ETA: 2:37 - loss: 0.1796 - accuracy: 0.9646"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Documents\\GitHub\\python_exer\\220927\\study_20s.ipynb 셀 43\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/GitHub/python_exer/220927/study_20s.ipynb#Y101sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m es \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/GitHub/python_exer/220927/study_20s.ipynb#Y101sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m mcp \u001b[39m=\u001b[39m ModelCheckpoint(filepath\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbest_model_gru.h5\u001b[39m\u001b[39m'\u001b[39m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Documents/GitHub/python_exer/220927/study_20s.ipynb#Y101sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m history \u001b[39m=\u001b[39m md4\u001b[39m.\u001b[39;49mfit(x_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(x_val, y_val), callbacks\u001b[39m=\u001b[39;49m[es, mcp])\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 생성 및 학습\n",
    "md4.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', patience=8)\n",
    "mcp = ModelCheckpoint(filepath='best_model_gru.h5', monitor='val_loss', save_best_only=True)\n",
    "history = md4.fit(x_train, y_train, epochs=100, validation_data=(x_val, y_val), callbacks=[es, mcp])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test 점수 : \n",
    "- best_model_lstm_dropout.h5 -> 0.7011 현재 2등\n",
    "- best_model_lstm_dropout2.h5 -> 0.7273 현재 1등"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('EV_PY39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1dde8d3f1fc6169eb2afb9c884f1482ff31994a855398e316a83a9dc8ff488b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
