# 12ì¥
library(MASS)
cor(cats$Bwt, cats$Hwt)

# ìƒê´€ê³„ìˆ˜ì˜ ì¢…ë¥˜
# í”¼ì–´ìŠ¨, ìŠ¤í”¼ì–´ë§Œ, ì¼„ë‹¬
cor(cats$Bwt, cats$Hwt, method='pearson')
cor(cats$Bwt, cats$Hwt, method='spearman')
cor(cats$Bwt, cats$Hwt, method='kendall')

# ìƒê´€ê³„ìˆ˜ì— ëŒ€í•œ ìœ ì˜ì„± ê²€ì¦ (2 ë³€ìˆ˜)
# cor.test ì‚¬ìš©
cor.test(cats$Bwt, cats$Hwt)

cor.test(~Bwt + Hwt, data=cats)

cor.test(~Bwt + Hwt, data=cats, subset=(Sex=='F'))

# 3ê°œ ì´ìƒì˜ ë³€ìˆ˜ê°„ì˜ ìƒê´€ê³„ìˆ˜ ìœ ì˜ì„± ê²€ì •
# corr.test ì‚¬ìš©
library(psych)

corr.test(iris[,-5])

print(corr.test(iris[,-5]), short=F)

# ìƒê´€ê´€ê³„ ë„í‘œ
library(psych)
pairs.panels(state.x77, bg='red', pch=21, hist.col='gold', main='correlation')

library(corrgram)
corrgram(state.x77, lower.panel = panel.pie, order=T, upper.panel = panel.conf)


# í¸ìƒê´€ê´€ê³„
# ë‘ ë³€ìˆ˜ ê°„ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•  ë•ŒëŠ” ë‹¤ë¥¸ ë³€ìˆ˜ì˜ ì˜í–¥ì„ ì£¼ì˜ ê¹Šê²Œ ì‚´í´ë´ì•¼ í•¨

# í¸ìƒê´€ê³„ìˆ˜ : ë‘ ë³€ìˆ˜ê°„ì˜ ìˆœìˆ˜í•œ ìƒê´€ê´€ê³„ë¥¼ íŒŒì•…í•˜ê¸° ìœ„í•œ ì§€í‘œ
colnames(mtcars)
mtcars2 <- mtcars[,c('mpg', 'cyl', 'hp', 'wt')]

cor(mtcars2)
# ì—°ë¹„ì™€ ë‚˜ë¨¸ì§€ 3ë³€ìˆ˜ëŠ” ë†’ì€ ìƒê´€ê´€ê³„ë¥¼ ë³´ì—¬

# ì—°ë¹„ì™€ ë§ˆë ¥ ê°„ì˜ í¸ìƒê´€ê³„ìˆ˜ êµ¬í•˜ê¸°
library(ggm)

# pcor (ë²¡í„°, ê³µë¶„ì‚°í–‰ë ¬)
# ë²¡í„°ì˜ ì²« ë‘ ì¸ë±ìŠ¤ëŠ” í¸ìƒê´€ê³„ìˆ˜ë¥¼ ê³„ì‚°í•  ë³€ìˆ˜, ë‚˜ë¨¸ì§€ëŠ” í†µì œí•  ë³€ìˆ˜
# ê³µë¶„ì‚°í–‰ë ¬ì€ covë¡œ ê³„ì‚°
pcor(c(1,3,2,4), cov(mtcars2))

# í¸ìƒê´€ê³„ìˆ˜ì— ëŒ€í•œ ìœ ì˜ì„± ê²€ì • 
# pcor.test(pcorí•¨ìˆ˜, q=í†µì œë³€ìˆ˜ ê°œìˆ˜, n=í–‰ ê°œìˆ˜)
pcor.test(pcor(c(1,3,2,4), cov(mtcars2)), q=2, n=nrow(mtcars2))
# p-valueëŠ” 0.14ë¡œ ê·€ë¬´ê°€ì„¤ì„ ê¸°ê°í•˜ì§€ ëª»í•œë‹¤. ê·¸ëŸ¬ë¯€ë¡œ
# mpgì™€ hpê°„ì—ëŠ” ìˆœìˆ˜í•œ ìƒê´€ê´€ê³„ëŠ” ì¡´ì¬x
install.packages('ppcor')
library(ppcor)

pcor.test(mtcars2['mpg'], mtcars2['hp'], mtcars2[c('cyl', 'wt')])

# 13ì¥
library(HistData)

df <- GaltonFamilies
str(df)
cor(df$midparentHeight,df$childHeight)
plot(jitter(df$midparentHeight),jitter(df$childHeight), col='coral', pch=19 )


model <-lm(childHeight~ midparentHeight, data=df)

abline(model, col='purple', lwd=3)
# íšŒê·€ ê³„ìˆ˜, ì„ í˜•íšŒê·€ì‹

# ì„±ë³„ë³„ë¡œ íšŒê·€ì„  

# íšŒê·€ë¶„ì„ regression analysis 
# ë…ë¦½ë³€ìˆ˜ì™€ ì¢…ì†ë³€ìˆ˜ì˜ ê´€ê³„ë¥¼ ì˜ ì„¤ëª…í•˜ëŠ” íšŒê·€ì‹ì„ ì°¾ëŠ” ê³¼ì •

# ë…ë¦½ë³€ìˆ˜ì™€ ì¢…ì†ë³€ìˆ˜ì˜ ê´€ê³„ë¥¼ ì„¤ëª… ë˜ëŠ” ì˜ˆì¸¡í•  ìˆ˜ ìˆë‹¤.

# ì”ì°¨(residual, error) : ì‹¤ì œë°ì´í„°ì˜ ê°’(ê´€ì¸¡ê°’) ê³¼ íšŒê·€ì‹ì˜ ê°’(ì˜ˆì¸¡ê°’)ê³¼ì˜ ì°¨ì´

# ëª¨í˜• ì í•© fitting a model : ë°ì´í„° ì „ì²´ë¥¼ ê³ ë ¤í–ˆì„ ë•Œ, ì”ì°¨ê°€ ê°€ì¥ ì‘ì€ ì§ì„ ì˜ ë°©ì •ì‹

# í‰ê· ì ˆëŒ€ì˜¤ì°¨ MAE mean absolute error
# í‰ê· ì œê³±ì˜¤ì°¨ MSE mean squared error
# ì œê³±ê·¼ í‰ê· ì œê³±ì˜¤ì°¨ RMSE rooted mean squared error

# ì”ì°¨ì œê³±í•© RSS 

x <- runif(n=100, min=0, max=100)
y <- 3*x +5 + rnorm(100, 0, 50)
plot(x,y, pch=19, col='hotpink')

cor(x,y)
model <-lm(y ~x)
?lm
abline(model, col='tomato', lwd=2)

summary(model)
# Estimate : ì˜ˆì¸¡ê°’, std.Error : í‘œì¤€ì˜¤ì°¨, 
# t value : ì”ì°¨ë“¤ì˜ ë¶„í¬ê°€ të¶„í¬ë¥¼ ë”°ë¥´ê¸° ë•Œë¬¸ì— t value ê°€ ë‚˜ì˜¨ë‹¤. 
# Prë¡œ ê¸°ìš¸ê¸°ì™€ ì ˆí¸ì˜ ìœ ì˜í™•ë¥ ì´ ë‚˜ì˜¨ë‹¤. 
# ì—¬ê¸°ì„œì˜ Prì˜ ê·€ë¬´ê°€ì„¤ì€ ìƒê´€ê´€ê³„ê°€ ì—†ë‹¤ ì´ë‹¤.
# ê·¸ë˜ì„œ Prì´ ë§¤ìš° ë‚®ê²Œ ë‚˜ì˜¤ë©´ ê·€ë¬´ê°€ì„¤ì€ ê¸°ê°ë˜ê³  ëŒ€ë¦½ê°€ì„¤ì´ ì±„íƒëœë‹¤. (ì¦‰ ìƒê´€ê´€ê³„ê°€ ìˆë‹¤.)
# Residual standard error ì”ì°¨ í‘œì¤€ ì˜¤ì°¨
# multiple r-sqaured  ì–´ëŠ ì •ë„ë¡œ ëª¨ë¸ì´ ì¢‹ì€ì§€ ì•Œë ¤ì¤Œ, ë³€ìˆ˜ê°€ 2ê°œì¼ ë•Œ ì‚¬ìš© (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)
# adjusted r-squared ì–´ëŠ ì •ë„ë¡œ ëª¨ë¸ì´ ì¢‹ì€ì§€ ì•Œë ¤ì¤Œ, ë³€ìˆ˜ê°€ ì—¬ëŸ¬ê°œì¼ ë•Œ ì‚¬ìš©(1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)

# F-statistic : F ë¶„í¬, p-value: ì´ íšŒê·€ì‹ ì „ì²´ê°€ ì“¸ë§Œí•œì§€ ì•„ë‹Œì§€ ì•Œë ¤ì¤Œ, ë‚®ì„ìˆ˜ë¡ ì˜ˆì¸¡ë ¥ì´ ì¢‹ë‹¤ê³  íŒë‹¨


abline ( a=1, b=5, col='coral', lwd=1, lty=2)

# 14. íšŒê·€ë¶„ì„ì˜ ìœ í˜•
# ë‹¨ìˆœíšŒê·€ë¶„ì„
# ìºë‚˜ë‹¤ì˜ ì¸êµ¬ì¡°ì‚¬ ë°ì´í„°: ë³€ìˆ˜ 6ê°œ, ê´€ì¸¡ê°’ 102ê°œ

library(car)
str(Prestige)
df <- Prestige

table(df$type)
barplot(table(df$type), col='tomato3')

hist(df$income, col='wheat', breaks=20)
shapiro.test(df$income)
hist(df$education, col='wheat', breaks=20)
shapiro.test(df$education)
hist(df$women, col='wheat', breaks=20)
shapiro.test(df$women)
hist(df$prestige, breaks=20)
shapiro.test(df$prestige)

plot(df[,-(5:6)])
cor(df[,-(5:6)])
colors()

model <-lm(income ~ education, data=df)
model2 <-lm(income ~ women, data=df)
model3 <-lm(income ~ prestige, data=df)
summary(model)

plot(income~education, data=df, col='tomato', pch='ğŸ…')
abline(model, col='skyblue', lwd=2)

par(mfrow=c(1,3))
plot(income~education, data=df, col='tomato', pch='ğŸ…')
abline(model, col='skyblue', lwd=2)
plot(income~women, data=df, col='orange', pch='ğŸ£')
abline(model2, col='skyblue', lwd=2)
plot(income~prestige, data=df, col='green', pch='ğŸ')
abline(model3, col='skyblue', lwd=2)
par(mfrow=c(1,1))

summary(resid(model))

# ì‹ ë¢°êµ¬ê°„ ë°˜í™˜
confint(model)
# íšŒê·€ê³„ìˆ˜ ë°˜í™˜
coef(model)
# ë¶„ì‚°ë¶„ì„í‘œ ë°˜í™˜
anova(model)
# ì˜ˆì¸¡ê°’ ë°˜í™˜
fitted(model)

# predict í•¨ìˆ˜ë¥¼ ì´ìš©í•´ì„œ ì˜ˆì¸¡
# ìƒˆë¡œìš´ ë°ì´í„° newdata ë„£ê¸°
prestige.new <- data.frame(education=c(5,10,15))
# ì˜ˆì¸¡
predict(model, newdata=prestige.new)
# interval= 95%ì‹ ë¢°êµ¬ê°„ ì¶œë ¥
predict(model, newdata=prestige.new, interval = 'confidence')

# ì„œë¸Œì…‹ ì¡°ê±´ì„ ì§€ì •í•˜ê³  ë‹¨ìˆœíšŒê·€ë¶„ì„
lm(income ~ education, data=Prestige, subset = (education > mean(education)))

lm(income ~ education, data=Prestige, subset = (education <= mean(education)))


# ë‹¤ì¤‘ íšŒê·€ë¶„ì„
# ì¢…ì†ë³€ìˆ˜ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë…ë¦½ë³€ìˆ˜ê°€ ì—¬ëŸ¬ê°œì¸ ê²½ìš° -> ë‹¤ì¤‘íšŒê·€ì‹
formula = income ~ education + women + prestige
model <-lm(formula, data=df)
summary(model)

formula = income ~ women + prestige
model <-lm(formula, data=df)
summary(model)

# ë‹¤í•­íšŒê·€ë¶„ì„: ë‹¨ìˆœíšŒê·€ë¶„ì„ì´ 1ì°¨í•­ì— ëŒ€í•´ì„œë§Œ í–ˆë‹¤ë©´, ë‹¤í•­íšŒê·€ë¶„ì„ì€ 2ì°¨ ì´ìƒì˜ í•­ì„ ê°€ì§„ ë‹¤í•­í•¨ìˆ˜ì— í”¼íŒ…ì‹œí‚¤ëŠ” íšŒê·€ë°©ë²•
model <- lm(income ~ education + I(education^2), data=Prestige)
summary(model)

plot(Prestige$income~Prestige$education, pch=19, col='darkorange', xlab='education', ylab='income', main= 'Education and income')
library(dplyr)
lines(arrange(data.frame(Prestige$education, fitted(model)), Prestige$education ), col='cornflowerblue', lwd=2)

library(stargazer) # ì •ë³´ë¥¼ ì˜ˆì˜ê²Œ ì¶œë ¥
stargazer(model, type='text')

# ì„ í˜• íšŒê·€ì— ê´€í•œ ê°€ì •
# ì„ í˜•ì„± ê°€ì •, ì •ê·œì„± ê°€ì •, ë“±ë¶„ì‚°ì„± ê°€ì •ì„ ì²´í¬ í•´ì£¼ëŠ” ê·¸ë˜í”„ plot(model)
par(mfrow=c(2,2))
plot(model)
par(mfrow=c(1,1))

model <- lm(income ~ education + I(education^2), data=df)
plot(income ~ education, data=df)

plot(income ~ education + I(education^2), data=df)
summary(model)
library(tidyverse)
with(df,lines(arrange(data.frame(education, fitted(model)), education)), col='tomato' )


# 15ì¥. íšŒê·€ëª¨ë¸ì˜ ì„¤ëª…ë ¥
df <- mtcars
str(df)
df <- mtcars[,1:6]
str(df)

plot(df, col='coral', pch=19)
cor(df)

library(corrgram)
corrgram(df)

model <- lm(mpg~., data=df)
summary(model)



# AIC : Akaike informalion criterion
# ì „ì§„ì„ íƒë²•, í›„ì§„ì„ íƒë²•, ë‹¨ê³„ë²•

camn <- lm(mpg~hp + wt+disp+drat,data=mtcars)
step(camn, direction = 'backward') 


# ì—°ìŠµë¬¸ì œ
df <- read.csv('train.csv')


names(df)
str(df)
length(names(df))


g <- c('SalePrice ~')
for (i in 1:80) {
  if (is.numeric(df[,i])) {
    g <- paste(g, names(df)[i], '+')
    print(paste(g, '+',names(df)[i]))
  }
}
g
formula <- SalePrice ~ Id + MSSubClass + LotFrontage + LotArea + OverallQual + OverallCond +YearBuilt + YearRemodAdd + MasVnrArea + BsmtFinSF1 + BsmtFinSF2 + BsmtUnfSF + TotalBsmtSF + X1stFlrSF +X2ndFlrSF + LowQualFinSF + GrLivArea + BsmtFullBath + BsmtHalfBath + FullBath + HalfBath +BedroomAbvGr + KitchenAbvGr + TotRmsAbvGrd + Fireplaces + GarageYrBlt + GarageCars + GarageArea +WoodDeckSF + OpenPorchSF + EnclosedPorch + X3SsnPorch + ScreenPorch + PoolArea + MiscVal + MoSold + YrSold 
camn <- lm(SalePrice ~., data=df)
step(camn, direction = 'backward') 


camn <- lm(formula=formula, data=df)
step(camn, direction = 'forward') 


# êµìˆ˜ë‹˜ ë°©ë²•
is.num <- c()
for (i in 1:80) {
  is.num[i] <- is.numeric(df[,i])
}

is.num
df <- df[, is.num]
df<- df[,-1]
dim(df)
df <- df[complete.cases(df),]  # ê²°ì¸¡ì¹˜ ì œê±°
dim(df)

model <- lm(SalePrice ~., data=df)
step(model, direction = 'backward')
summary(model)

model <- lm(SalePrice ~ 1, data=df)
step(model, direction = 'forward', scope = list(lower = ~1,
                                                upper = ~MSSubClass + LotFrontage + LotArea + OverallQual + OverallCond +YearBuilt + YearRemodAdd + MasVnrArea + BsmtFinSF1 + BsmtFinSF2 + BsmtUnfSF + TotalBsmtSF + X1stFlrSF +X2ndFlrSF + LowQualFinSF + GrLivArea + BsmtFullBath + BsmtHalfBath + FullBath + HalfBath +BedroomAbvGr + KitchenAbvGr + TotRmsAbvGrd + Fireplaces + GarageYrBlt + GarageCars + GarageArea +WoodDeckSF + OpenPorchSF + EnclosedPorch + X3SsnPorch + ScreenPorch + PoolArea + MiscVal + MoSold + YrSold  )) 

# íšŒê·€ë¶„ì„ì„ ìœ„í•œ ë³€ìˆ˜ê°€ ìˆ˜ì¹˜í˜•ì´ ì•„ë‹ ë•Œ, 
# ë”ë¯¸ ë³€ìˆ˜ë¡œ ë³€í™˜í•˜ì—¬ íšŒê·€ë¶„ì„ì„ í•  ìˆ˜ ìˆìŒ

# contrasts : ë”ë¯¸ë³€ìˆ˜ì˜ ì½”ë”© êµ¬ì¡° í™•ì¸ ê°€ëŠ¥
df <- InsectSprays
str(df)
lm(count ~ spray, data=df)
model <- lm(count ~ spray, data=df)  # ë”ë¯¸ ì¸ì½”ë”©ì„ ì´ìš©í•´ì„œ 5ê°œì˜ ê°’ì´ ë‚˜ì˜¨ë‹¤.
summary(model)

contrasts(df$spray)  # ë”ë¯¸ ë³€ìˆ˜ ë³´ëŠ”ë²•

df <- mtcars[,1:6]
str(df)
df$cyl <- factor(df$cyl)
head(df)

table(df$cyl)

model <- lm(mpg~., data=df)
summary(model)


plot(iris[,c(1,5)])

df <- split(iris, f=iris$Species)
df <-rbind(df$setosa, df$versicolor)
plot(df[,c(3,5)])

# 16ì¥. ì„ í˜•ëª¨ë¸ì˜ ì¼ë°˜í™”
# ì´í•­ ë¡œì§€ìŠ¤í‹± í•¨ìˆ˜

# ìµœëŒ€ ìš°ë„ë²•

# í‘¸ì•„ì†¡ íšŒê·€ë¶„ì„ : ê²°ê³¼ë³€ìˆ˜ê°€ íŠ¹ì • ê¸°ê°„ ì´ë‚´ì˜ ì‚¬ê±´ë°œìƒíšŸìˆ˜ì¸ ê²½ìš°ì— ì ìš©
library(robust)
data("breslow.dat")
str(breslow.dat)

seizure <- breslow.dat[c('Base', 'Age', 'Trt', 'sumY')]
summary(seizure)

hist(seizure$sumY, breaks=20)
# ì¢…ì†ë³€ìˆ˜ê°€ íšŸìˆ˜ì´ê¸° ë•Œë¬¸ì— í‘¸ì•„ì†¡ ë¶„í¬ë¥¼ ì‚¬ìš©
model <- glm(sumY~ Base + Age + Trt, data=seizure, family=poisson)
summary(model)

# ì‹ ì•½ì´ íš¨ê³¼ê°€ ìˆë‹¤ê³  ì£¼ì¥í•´ë„ ë¬´ë°©í•˜ë‹¤.

coef(model)

exp(coef(model))
# ì´ ëª¨ë¸ì´ ì˜ ë§ëŠ”ì§€ í‰ê°€í•˜ë ¤ë©´, ì„ í˜•ì¼ë•Œë‘ì€ ë˜ ë‹¤ë¥´ë‹¤. (ë” ë³µì¡)

# ì•½ì„ ì²˜ë°©ë°›ì€ í™˜ì ì§‘ë‹¨ì€ í”Œë¼ì‹œë³´ë¥¼ ë³µìš©í•œ í™˜ì ì§‘ë‹¨ì— ë¹„í•´ ë°œì‘íšŸìˆ˜ê°€ 14.2%ê°ì†Œ

# ì´í•­ ë¡œì§€ìŠ¤í‹± íšŒê·€ë¶„ì„ binomial logistic regression model :

df <- split(iris, f=iris$Species)
df <-rbind(df$setosa, df$versicolor)
plot(df[,c(3,5)])
df$Species <- as.numeric(df$Species) -1

model <- glm(Species ~ Petal.Length, data=df, family=binomial(link = 'logit'))
abline(model, col='red')

# ë¡œì§€ìŠ¤í‹±ì€ ë¶„ë¥˜ê²°ê³¼ê°€ ë§ëŠ”ì§€ í‹€ë¦°ì§€ êµ¬ë³„í•˜ëŠ” ê²ƒì´ ì¤‘ìš”
# í˜¼ë™ í–‰ë ¬ confusion matrix : ì´ì§„ ë¶„ë¥˜ê¸°ê°€ ë¶„ë¥˜í•  ë•Œ, ì–¼ë§ˆë‚˜ ë§ì´ í—·ê°ˆë ¸ëŠ”ê°€ë¥¼ ë‚˜íƒ€ëƒ„

# ì •ë°€ë„ type 1 error, ì¬í˜„ìœ¨ type 2 error
# ROC ê³¡ì„  : ì´ì§„ ë¶„ë¥˜ì˜ ê²°ê³¼ì—ì„œ fpë¹„ìœ¨ê³¼ tpë¹„ìœ¨ì˜ ê´€ê³„ë¥¼ ê·¸ë¦° ê³¡ì„ , 
# AUC (area under curve) : rocê³¡ì„ ì˜ í•˜ë¶€ ë©´ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ì„±ëŠ¥ í‰ê°€ ì§€í‘œ


# exer penguin

library(palmerpenguins)
pg <- penguins
str(pg)
pg <- pg[complete.cases(pg), -8]
str(pg)    #ğŸ§
dim(pg)

# Adelieì¸ì§€ Adelieê°€ ì•„ë‹Œì§€ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì´í•­ìœ¼ë¡œ species ë¶„ë¥˜
pg$is.adelie <- factor(
  ifelse(pg$species == 'Adelie',
         'Yes', 'No'))

barplot(table(pg$is.adelie))

pg <- pg[,-1]
str(pg)

model <- glm(is.adelie~., data=pg, family = binomial(link = 'logit'))
summary(model)
# 0ì´ ë  í™•ë¥ , 1ì´ ë  í™•ë¥  -> fitted
model$fitted.values
pg$pred <- factor(ifelse(model$fitted.values > 0.5, 'Yes', 'No'))

table(pg$is.adelie, pg$pred)  # adelieì¸ì§€ ì•„ë‹Œì§€ ì •í™•í•˜ê²Œ ê³„ì‚°í–ˆë‹¤.


df <- iris
df$Species <- factor(ifelse(df$Species == 'virginica', 'Yes', 'No'))
table(df$Species)

model <- glm(Species~., data=df, family=binomial(link='logit'))
summary(model)
df$pred <- factor(ifelse(model$fitted.values > 0.5, 'Yes', 'No'))
# í˜¼ë™í–‰ë ¬
tab <-table(df$Species, df$pred)
TP <- tab[2,2]
TN <- tab[1,1]
FP <- tab[2,1]
FN <- tab[1,2]
accuracy <- (TP + TN)/(TP+TN+FP+FN)
precision <-TP / (TP+FP)
recall <- TP / (TP+FN)
F1.score <- 2* precision * recall / (precision+recall)
# AUC êµ¬í•˜ê¸° -> pROC ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ rocí•¨ìˆ˜ í•„ìš”
library(pROC)
roc(Species ~ model$fitted.values, data=df, plot=T, main='ROC curve', col='tomato')
# 0.9986 -> 1ì— ê°€ê¹Œìš¸ ìˆ˜ë¡ ì¢‹ì€ ì´ì§„ ë¶„ë¥˜ê¸°ë¼ëŠ” ëœ» (0.8ì´ìƒì´ë©´ ê´œì°®ì„ ì§€í‘œ)

# p-value, ì”ì°¨ ë“±ì˜ ì§€í‘œë¥¼ í™œìš©í•  ìˆ˜ê°€ ì—†ë‹¤.
# ëŒ€ì‹ , ì‹¤ì œë¡œ ê°’ì„ ë„£ì–´ë³´ê³  ì˜ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸ -> í˜¼ë™í–‰ë ¬ ì œì‘

